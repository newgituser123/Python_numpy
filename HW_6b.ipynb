{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecdd50b",
   "metadata": {},
   "source": [
    "# Home work #6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676c7ee",
   "metadata": {},
   "source": [
    "## Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a8133",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f392a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5001fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "y = pd.DataFrame(boston.target, columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2021cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20039e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c8fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b9c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6693702691495608"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05b6f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 66.94 %\n"
     ]
    }
   ],
   "source": [
    "lr_r2 = r2_score(y_pred, y_test)\n",
    "print(f\"R^2: {lr_r2*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da606b",
   "metadata": {},
   "source": [
    "#### Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e75c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b7764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "??RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d5537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=12,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6bf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])\n",
    "model_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe1c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 84.79 %\n"
     ]
    }
   ],
   "source": [
    "RF_r2 = r2_score(model_pred, y_test)\n",
    "print(f\"R^2: {RF_r2*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5675820",
   "metadata": {},
   "source": [
    "Коэфф. детерминации у модели построенной с помощью RandomForest >> R2 модели Линейной регресии => RandomForest лучше прогнозирует"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac085a",
   "metadata": {},
   "source": [
    "#### *Задание 3\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cfa45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_train.columns).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80cbe93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c3f04c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_size_inches(10, 8)\n",
    "\n",
    "forest_importances.plot(yerr=std, kind='barh', ax=ax, width=0.8, label=\"Значимость переменных\")\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc724dc3",
   "metadata": {},
   "source": [
    "Наибольшую значимость имеют LSTAT, RM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcedf2",
   "metadata": {},
   "source": [
    "#### *Задание 4\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.<br>\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.<br>\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:<br>\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.<br>\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.<br>\n",
    "Создайте объект Series под названием y из столбца Class.<br>\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: <br>test_size=0.3, random_state=100, stratify=y.<br>\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.<br>\n",
    "Просмотрите информацию о их форме.<br>\n",
    "Для поиска по сетке параметров задайте такие параметры:<br>\n",
    "parameters = [{'n_estimators': [10, 15],<br>\n",
    "'max_features': np.arange(3, 5),<br>\n",
    "'max_depth': np.arange(4, 7)}]<br>\n",
    "Создайте модель GridSearchCV со следующими аргументами:<br>\n",
    "estimator=RandomForestClassifier(random_state=100),<br>\n",
    "param_grid=parameters,<br>\n",
    "scoring='roc_auc',<br>\n",
    "cv=3.<br>\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).<br>\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.<br>\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.<br>\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.<br>\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36f58f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Data\\GB\\Python_Numpy\\CreditCardFraudDetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e9dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d24e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "740b2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7941f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = df.Class.value_counts(normalize=True) #If True - returne frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2eb8700d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7761cb4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c326009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40154220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6feb5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b1979e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c18daff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "454a3d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 30)\n",
      "(85443, 30)\n",
      "(199364,)\n",
      "(85443,)\n"
     ]
    }
   ],
   "source": [
    "for d in [X_train, X_test, y_train, y_test]:\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fd2e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{\n",
    "    'n_estimators': [10, 15],\n",
    "    'max_features': np.arange(3, 5),\n",
    "    'max_depth': np.arange(4, 7)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae486726",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=100),\n",
    "    param_grid=parameters,\n",
    "    scoring='roc_auc',\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99425e2b",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ca36815",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
       "                          'max_features': array([3, 4]),\n",
       "                          'n_estimators': [10, 15]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b13145a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddf4b761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)\n",
    "\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "743a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19f8f562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96346008e-01, 3.65399208e-03],\n",
       "       [9.99317613e-01, 6.82386899e-04],\n",
       "       [9.99719232e-01, 2.80768418e-04],\n",
       "       ...,\n",
       "       [9.99719232e-01, 2.80768418e-04],\n",
       "       [9.99453497e-01, 5.46502595e-04],\n",
       "       [9.92811217e-01, 7.18878274e-03]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcaca6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ef4006f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00365399, 0.00068239, 0.00028077, ..., 0.00028077, 0.0005465 ,\n",
       "       0.00718878])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1649d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62ca0f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945919250043173"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
